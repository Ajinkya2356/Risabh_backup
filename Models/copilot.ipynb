{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(904, 340)\n",
      "(1652, 604)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "\n",
    "# Define the ESRGAN Model (RRDBNet)\n",
    "class RRDBNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, nf, nb, gc=32):\n",
    "        super(RRDBNet, self).__init__()\n",
    "        RRDB_block_f = lambda nf, gc: RRDB(nf, gc)\n",
    "        self.conv_first = nn.Conv2d(in_channels, nf, 3, 1, 1, bias=True)\n",
    "        self.RRDB_trunk = self.make_layer(RRDB_block_f, nb, nf, gc)\n",
    "        self.trunk_conv = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
    "        self.upconv1 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
    "        self.upconv2 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
    "        self.conv_last = nn.Conv2d(nf, out_channels, 3, 1, 1, bias=True)\n",
    "\n",
    "    def make_layer(self, block, num_blocks, *args):\n",
    "        layers = []\n",
    "        for _ in range(num_blocks):\n",
    "            layers.append(block(*args))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        fea = self.conv_first(x)\n",
    "        trunk = self.trunk_conv(self.RRDB_trunk(fea))\n",
    "        fea += trunk\n",
    "        fea = torch.nn.functional.interpolate(fea, scale_factor=2, mode=\"nearest\")\n",
    "        fea = torch.nn.functional.interpolate(fea, scale_factor=2, mode=\"nearest\")\n",
    "        fea = self.conv_last(fea)\n",
    "        return fea\n",
    "\n",
    "\n",
    "# Load the ESRGAN Model\n",
    "def load_esrgan_model(model_path=\"RRDB_ESRGAN_x4.pth\"):\n",
    "    model = RRDBNet(3, 3, 64, 23, gc=32)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "# Upscale the image with ESRGAN\n",
    "def upscale_image_with_esrgan(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    input_tensor = F.to_tensor(Image.fromarray(image)).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        output_tensor = model(input_tensor).squeeze(0)\n",
    "    output_image = F.to_pil_image(output_tensor.clamp(0, 1))\n",
    "    return np.array(output_image)\n",
    "\n",
    "\n",
    "# Paths to the images\n",
    "input_image_path = \"./generate_images/bad_m2_1.png\"\n",
    "master_image_path = \"./Meter.jpg\"\n",
    "\n",
    "# Load the images\n",
    "input_image = cv2.imread(input_image_path)\n",
    "master_image = cv2.imread(master_image_path)\n",
    "\n",
    "# Load the ESRGAN model\n",
    "esrgan_model = load_esrgan_model(\"RRDB_ESRGAN_x4.pth\")  # Path to the ESRGAN model\n",
    "\n",
    "# Upscale the images\n",
    "input_image_hr = upscale_image_with_esrgan(input_image, esrgan_model)\n",
    "master_image_hr = upscale_image_with_esrgan(master_image, esrgan_model)\n",
    "\n",
    "# Continue with grayscale conversion, thresholding, and contour detection\n",
    "input_gray = cv2.cvtColor(input_image_hr, cv2.COLOR_BGR2GRAY)\n",
    "master_gray = cv2.cvtColor(master_image_hr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Thresholding\n",
    "_, input_thresh = cv2.threshold(input_gray, 128, 255, cv2.THRESH_BINARY_INV)\n",
    "_, master_thresh = cv2.threshold(master_gray, 128, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Contour Detection\n",
    "input_contours, _ = cv2.findContours(input_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "master_contours, _ = cv2.findContours(master_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Bounding Box Extraction\n",
    "def get_segment_bounding_boxes(contours):\n",
    "    bounding_boxes = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        bounding_boxes.append((x, y, w, h))\n",
    "    return bounding_boxes\n",
    "\n",
    "\n",
    "input_bounding_boxes = get_segment_bounding_boxes(input_contours)\n",
    "master_bounding_boxes = get_segment_bounding_boxes(master_contours)\n",
    "\n",
    "# Matching Segments with Tolerance\n",
    "position_tolerance = 20\n",
    "size_tolerance = 0.14\n",
    "\n",
    "def is_segment_present(master_box, input_boxes, position_tolerance, size_tolerance):\n",
    "    mx, my, mw, mh = master_box\n",
    "    for ix, iy, iw, ih in input_boxes:\n",
    "        if (abs(mx - ix) <= position_tolerance and\n",
    "            abs(my - iy) <= position_tolerance and\n",
    "            abs(mw - iw) / mw <= size_tolerance and\n",
    "            abs(mh - ih) / mh <= size_tolerance):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# Check and Mark Missing Segments\n",
    "all_segments_present = True\n",
    "for master_box, master_contour in zip(master_bounding_boxes, master_contours):\n",
    "    if not is_segment_present(master_box, input_bounding_boxes, position_tolerance, size_tolerance):\n",
    "        all_segments_present = False\n",
    "        cv2.drawContours(master_image_hr, [master_contour], -1, (0, 0, 255), 2)\n",
    "\n",
    "if all_segments_present:\n",
    "    print(\"All segments in the master image are present in the input image.\")\n",
    "else:\n",
    "    print(\"Some segments in the master image are missing in the input image.\")\n",
    "\n",
    "# Display Results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Input Image (High Resolution)\")\n",
    "plt.imshow(cv2.cvtColor(input_image_hr, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Master Image with Missing Segments Marked\")\n",
    "plt.imshow(cv2.cvtColor(master_image_hr, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cache the ESRGAN model\n",
    "esrgan_model = None\n",
    "\n",
    "def load_esrgan_model():\n",
    "    global esrgan_model\n",
    "    if esrgan_model is None:\n",
    "        esrgan_model = hub.load(\"https://tfhub.dev/captain-pool/esrgan-tf2/1\")\n",
    "    return esrgan_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Image at path {image_path} could not be loaded.\")\n",
    "    return image\n",
    "\n",
    "def apply_super_resolution(image):\n",
    "    # Load the ESRGAN model\n",
    "    model = load_esrgan_model()\n",
    "    # Convert the image to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    # Convert the image to a tensor\n",
    "    image_tensor = tf.convert_to_tensor(image_rgb, dtype=tf.float32)\n",
    "    image_tensor = tf.expand_dims(image_tensor, 0)\n",
    "    # Apply the ESRGAN model\n",
    "    sr_image_tensor = model(image_tensor)\n",
    "    sr_image = tf.squeeze(sr_image_tensor).numpy()\n",
    "    # Convert the image back to grayscale\n",
    "    sr_image_gray = cv2.cvtColor(sr_image.astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    return sr_image_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_contours(image, threshold_value):\n",
    "    # Increase image contrast\n",
    "    alpha = 1.5  # Contrast control (1.0-3.0)\n",
    "    beta = 0     # Brightness control (0-100)\n",
    "    adjusted = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise and improve contour detection\n",
    "    blurred = cv2.GaussianBlur(adjusted, (5, 5), 0)\n",
    "\n",
    "    # Apply morphological operations\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    morph = cv2.morphologyEx(blurred, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Use the morphed image for thresholding and contour detection\n",
    "    _, binary = cv2.threshold(morph, threshold_value, 255, cv2.THRESH_BINARY_INV)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours_detected = []\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 10:\n",
    "            contours_detected.append(contour)\n",
    "    return contours_detected\n",
    "\n",
    "def draw_contours(image, contours):\n",
    "    # Draw contours on the image\n",
    "    image_with_contours = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.drawContours(image_with_contours, contours, -1, (0, 255, 0), 2)\n",
    "    return image_with_contours\n",
    "\n",
    "def draw_missing_segments(master_contours, captured_contours, master_image):\n",
    "    # Compare contours to find missing segments\n",
    "    missing_contours = []\n",
    "    for master_contour in master_contours:\n",
    "        found = False\n",
    "        for captured_contour in captured_contours:\n",
    "            if cv2.matchShapes(master_contour, captured_contour, cv2.CONTOURS_MATCH_I1, 0.0) < 0.1:  # Shape matching threshold\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            missing_contours.append(master_contour)\n",
    "\n",
    "    # Draw missing segments\n",
    "    for contour in missing_contours:\n",
    "        cv2.drawContours(master_image, [contour], -1, (0, 0, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(904, 340)\n",
      "(1652, 604)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_image_path = '../Analog/train/class 1/good_1.png'\n",
    "captured_image_path = '../Analog/train/class 0/bad_m_576.png'\n",
    "\n",
    "# Preprocess the images\n",
    "try:\n",
    "    master_image = preprocess_image(master_image_path)\n",
    "    captured_image = cv2.imread(captured_image_path)\n",
    "    if captured_image is None:\n",
    "        raise ValueError(f\"Image at path {captured_image_path} could not be loaded.\")\n",
    "    captured_image_gray = preprocess_image(captured_image_path)\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "    exit(1)\n",
    "\n",
    "# Apply super-resolution\n",
    "master_image_sr = apply_super_resolution(master_image)\n",
    "captured_image_sr = apply_super_resolution(captured_image_gray)\n",
    "\n",
    "print(master_image_sr.shape)\n",
    "print(captured_image_sr.shape)\n",
    "\n",
    "# Convert the captured image to BGR for threshold selection\n",
    "captured_image_bgr = cv2.cvtColor(captured_image_gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "# Select the threshold value dynamically\n",
    "threshold_value = select_threshold(captured_image_bgr)\n",
    "\n",
    "# Find contours\n",
    "master_contours = find_contours(master_image_sr, threshold_value)\n",
    "captured_contours = find_contours(captured_image_sr, threshold_value)\n",
    "\n",
    "# Draw contours on the images\n",
    "master_image_with_contours = draw_contours(master_image_sr, master_contours)\n",
    "captured_image_with_contours = draw_contours(captured_image_sr, captured_contours)\n",
    "\n",
    "# Draw missing segments\n",
    "draw_missing_segments(master_contours, captured_contours, master_image_sr)\n",
    "\n",
    "# Resize images for better visibility\n",
    "master_image_resized = cv2.resize(master_image_with_contours, (150, 418))\n",
    "captured_image_resized = cv2.resize(captured_image_with_contours, (150, 418))\n",
    "captured_image_with_missing_segments_resized = cv2.resize(master_image_sr, (150, 418))\n",
    "\n",
    "# Display the images\n",
    "cv2.imshow('Master Image with Contours', master_image_resized)\n",
    "cv2.imshow('Captured Image with Contours', captured_image_resized)\n",
    "cv2.imshow('Captured Image with Missing Segments', captured_image_with_missing_segments_resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the results\n",
    "cv2.imwrite('master_image_with_contours.jpg', master_image_with_contours)\n",
    "cv2.imwrite('captured_image_with_contours.jpg', captured_image_with_contours)\n",
    "cv2.imwrite('captured_image_with_missing_segments.jpg', captured_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
